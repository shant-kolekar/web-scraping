{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the dataset.\n",
    "    * Remove NA values\n",
    "    * Take Overall sentiment of the review, and add new column where each record is given either positive, negative or neutral sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import json\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that loads a lexicon of positive words to a set and returns the set\n",
    "def loadLexicon(fname):\n",
    "    newLex = set()\n",
    "    lex_conn = open(fname)\n",
    "\n",
    "    # add every word in the file to the set\n",
    "    for line in lex_conn:\n",
    "        newLex.add(line.strip())  # remember to strip to remove the lin-change character\n",
    "    lex_conn.close()\n",
    "    return newLex\n",
    "\n",
    "\n",
    "def lexicalAnalysis(sentences, posLex, negLex):\n",
    "    nouns_in_review = {}\n",
    "    for sentence in sentences:  # for each sentence\n",
    "        words = word_tokenize(sentence)  # split the review into words\n",
    "        tagged_words = nltk.pos_tag(words)  # POS tagging for the words in the sentence\n",
    "        nouns_in_sentence = set()  # set of all the nouns in the sentence\n",
    "        tags = {}  # positive and negative of the sentence\n",
    "        for tagged_word in tagged_words:\n",
    "            # print(tagged_word)\n",
    "            if tagged_word[1].startswith('NN'):  # if the word is a noun\n",
    "                noun = tagged_word[0].lower()  # lower case the noun\n",
    "                if len(noun) < 3: continue  # ignore nouns with less than 3 characters\n",
    "                nouns_in_sentence.add(noun)  # add the noun to the set\n",
    "\n",
    "            positive_count = tags.get('positive', 0)\n",
    "            negative_count = tags.get('negative', 0)\n",
    "\n",
    "            if tagged_word[1].startswith('JJ'):\n",
    "                if tagged_word[0].lower() in posLex:\n",
    "                    tags.update({'positive': positive_count + 1})\n",
    "\n",
    "                if tagged_word[0].lower() in negLex:\n",
    "                    tags.update({'negative': negative_count + 1})\n",
    "                    \n",
    "            if tagged_word[1].startswith('VB'):\n",
    "                if tagged_word[0].lower() in posLex:\n",
    "                    tags.update({'positive': positive_count + 1})\n",
    "\n",
    "                if tagged_word[0].lower() in negLex:\n",
    "                    tags.update({'negative': negative_count + 1})\n",
    "\n",
    "        nouns_list = list(nouns_in_sentence)\n",
    "        for n in nouns_list:\n",
    "            cur_tags = nouns_in_review.get(n, {})\n",
    "            nouns_in_review.update({\n",
    "                n: {\n",
    "                    'positive': tags.get('positive', 0) + cur_tags.get('positive', 0),\n",
    "                    'negative': tags.get('negative', 0) + cur_tags.get('negative', 0)\n",
    "                }\n",
    "            })\n",
    "\n",
    "    return nouns_in_review\n",
    "\n",
    "\n",
    "def parse(text):\n",
    "    # load the positive and negative lexicons into sets\n",
    "    posLex = loadLexicon('positive-words.txt')\n",
    "    negLex = loadLexicon('negative-words.txt')\n",
    "    sentences = sent_tokenize(text)  # split the review into sentences\n",
    "    sentiment = lexicalAnalysis(sentences, posLex, negLex)\n",
    "    return sentiment\n",
    "\n",
    "\n",
    "def conclude_sentiment_per_noun(sentiment_map):\n",
    "    positive = 0\n",
    "    negative = 0\n",
    "    for noun in sentiment_map.keys():\n",
    "        if (sentiment_map[noun]['positive'] - sentiment_map[noun]['negative']) > 0:\n",
    "            positive += 1\n",
    "        else:\n",
    "            negative += 1\n",
    "\n",
    "    if (positive - negative) > 0:\n",
    "        return 'positive'\n",
    "    elif (positive - negative) == 0:\n",
    "        return 'neutral'\n",
    "    else:\n",
    "        return 'negative'\n",
    "\n",
    "\n",
    "def clean_interviews():\n",
    "    interviews_file = open('tcs_interviews.json')\n",
    "    interviews = json.load(interviews_file)\n",
    "    cleaned_interviews = []\n",
    "\n",
    "    for item in interviews:\n",
    "        if not ((item['level_tag'] == 'NA') or (item['exp_tag'] == 'NA') or (item['offer_tag'] == 'NA')):\n",
    "            sentiment_map = parse(item['text'])\n",
    "            sentiment1 = conclude_sentiment_per_noun(sentiment_map)\n",
    "            item['sentiment'] = sentiment1\n",
    "            cleaned_interviews.append(item)\n",
    "\n",
    "    clean_file = open(\"tcs_interviews_clean.json\", \"w\")\n",
    "    json.dump(cleaned_interviews, clean_file, indent=6)\n",
    "\n",
    "    clean_file.close()\n",
    "    interviews_file.close()\n",
    "\n",
    "\n",
    "# def checkDiff():\n",
    "#     interviews_file = open('tcs_interviews_clean.json')\n",
    "#     interviews = json.load(interviews_file)\n",
    "#     count = 0\n",
    "#     for interview in interviews:\n",
    "#         if interview['overall_sentiment'] != interview['per_noun_sentiment']:\n",
    "#             count += 1\n",
    "\n",
    "#     print(count) # No. of mismatch sentiments: 2354\n",
    "\n",
    "\n",
    "# checkDiff()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned and saved the data to tcs_interviews_clean.json\n"
     ]
    }
   ],
   "source": [
    "clean_interviews()\n",
    "print('Cleaned and saved the data to tcs_interviews_clean.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
